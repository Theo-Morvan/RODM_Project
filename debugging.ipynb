{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"src/struct/distance.jl\")\n",
    "include(\"src/new_functions.jl\")\n",
    "include(\"src/merge.jl\")\n",
    "include(\"src\\\\utilities.jl\")\n",
    "using DataFrames, Random\n",
    "using DataStructures\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using LinearAlgebra\n",
    "using LazySets\n",
    "using Polyhedra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: int64 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: int64 not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\32mor\\OneDrive\\Documents\\IPP M2\\OR\\Projet_RODM_2023\\RODM_Project\\debugging.ipynb:33"
     ]
    }
   ],
   "source": [
    "function compute_dataframe_classes(\n",
    "    cluster_interest::Int64,\n",
    "    clusterId::Vector{Int64},\n",
    "    y::Vector{Int64}\n",
    ")\n",
    "    count_classes_in_clusters = StatsBase.countmap(y[findall(x->x==cluster_interest, clusterId)])\n",
    "    y_cluster = y[findall(x->x==cluster_interest, clusterId)]\n",
    "    df = DataFrame()\n",
    "    df.\"classes\" = collect(keys(count_classes_in_clusters))\n",
    "    df.\"count_classes\" = collect(values(count_classes_in_clusters))\n",
    "    df = sort(df, [:count_classes], rev=true)\n",
    "    return (df, y_cluster)\n",
    "end\n",
    "\n",
    "function detect_points_small_classes(\n",
    "    cluster_interest::Int64,\n",
    "    clusterId::Vector{Int64},\n",
    "    y::Vector{Int64}\n",
    ")\n",
    "    points_in_cluster = findall(x->x==cluster_interest, clusterId)\n",
    "    points_reckon_with = Vector{Int64}([])\n",
    "    points_sideline = Vector{Int64}([])\n",
    "    for (i, point) in enumerate(points_in_cluster)\n",
    "        if y[point] != main_class\n",
    "            push!(points_sideline,i )\n",
    "        else\n",
    "            push!(points_reckon_with, i)\n",
    "        end\n",
    "    end\n",
    "    return (points_reckon_with, points_sideline)\n",
    "end\n",
    "\n",
    "function trimming_cluster(\n",
    "    clusters::Vector{Cluster},\n",
    "    cluster_interest::Int64,\n",
    "    points_reckon_with::Vector{Int64},\n",
    "    points_sideline::Vector{Int64},\n",
    ")\n",
    "    matrix_interest = clusters[cluster_interest].x\n",
    "    size(matrix_interest, 1)\n",
    "    vectors_cluster = [matrix_interest[i,:] for i in 1:size(matrix_interest,1)]\n",
    "    vectors_cluster[points_reckon_with]\n",
    "    hull = LazySets.convex_hull(vectors_cluster[points_reckon_with])\n",
    "    for i in 1:length(points_sideline)\n",
    "        println(i, \" \",element(Singleton(vectors_cluster[points_sideline[i]])) ∈ VPolytope(hull))\n",
    "        if element(Singleton(vectors_cluster[points_sideline[i]])) ∈ VPolytope(hull)\n",
    "            push!(points_reckon_with,  points_sideline[i])\n",
    "        end\n",
    "    end\n",
    "    sort!(points_reckon_with)\n",
    "    points_to_be_taken_out_cluster = points_sideline[points_sideline .∉ Ref(points_reckon_with)]\n",
    "    new_clusters = Vector{Cluster}([])\n",
    "    point_cluster  = points_reckon_with[1]\n",
    "    trimmed_cluster = Cluster(point_cluster, matrix_interest, y_cluster)\n",
    "    for point_cluster in points_reckon_with[2:end]\n",
    "        new_cluster = Cluster(point_cluster, matrix_interest, y_cluster)\n",
    "        merge!(trimmed_cluster, new_cluster)\n",
    "    end\n",
    "\n",
    "    for point_cluster in points_to_be_taken_out_cluster\n",
    "        new_cluster = Cluster(point_cluster, matrix_interest, y_cluster)\n",
    "        push!(clusters, new_cluster)\n",
    "    end\n",
    "    clusters[cluster_interest] = trimmed_cluster\n",
    "    return clusters\n",
    "end\n",
    "\n",
    "function update_clusters(\n",
    "    clusters:Vector{Cluster},\n",
    "    cluster_interest::Int64,\n",
    "    clusterId::Vector{Int64},\n",
    "    y::Vector{Int64},\n",
    ")\n",
    "    df, y_cluster = compute_dataframe_classes(cluster_interest, clusterId, y)\n",
    "    if size(df)[1]>1\n",
    "        points_reckon_with, points_sideline =detect_points_small_classes(cluster_interest, clusterId, y_cluster)\n",
    "        clusters = trimming_cluster(clusters, cluster_interest,points_reckon_with, points_sideline)\n",
    "        return clusters\n",
    "    else\n",
    "        return clusters\n",
    "    end\n",
    "end\n",
    "\n",
    "function ConvexHullMerge(\n",
    "    x::Matrix{float64}, \n",
    "    y::Vector{Int}, \n",
    "    max_elements_small_classes::Int64,\n",
    "    num_clusters::Int64,\n",
    ")\n",
    "    n = length(y)\n",
    "    m = length(x[1,:])\n",
    "    clusters = Vector{Cluster}([])\n",
    "    for dataId in 1:size(x,1)\n",
    "        push!(clusters, Cluster(dataId, x,y))\n",
    "    end\n",
    "    clusterId = collect(1:n) #On obtient un vecteur 1,2..., qui correspond pour chaque cluster à son clusterId\n",
    "    distances = Vector{Distance}([])\n",
    "    for id1 in 1:n-1\n",
    "        for id2 in id1+1:n\n",
    "            push!(distances, Distance(id1, id2, x))\n",
    "        end\n",
    "    end\n",
    "    sort!(distances, by = v ->v.distance)\n",
    "    remainingClusters=n\n",
    "    distanceId = 1\n",
    "    n_epochs = 1\n",
    "    c1_bis = Nothing\n",
    "    c2_bis = Nothing\n",
    "    i = 1\n",
    "    a=i\n",
    "    \n",
    "\n",
    "    while remainingClusters>= num_clusters\n",
    "        distance = distances[distanceId]\n",
    "        cId1 =clusterId[distance.ids[1]]\n",
    "        cId2 = clusterId[distance.ids[2]]\n",
    "        if cId1 != cId2\n",
    "            c1 = clusters[cId1]\n",
    "            c2 = clusters[cId2]\n",
    "            count_classes_in_clusters = StatsBase.countmap([y[c2.dataIds]; y[c1.dataIds]])\n",
    "            df = DataFrame()\n",
    "            df.\"classes\" = collect(keys(count_classes_in_clusters))\n",
    "            df.\"count_classes\" = collect(values(count_classes_in_clusters))\n",
    "            df = sort(df, [:count_classes], rev=true)\n",
    "            # if sum(df[df.\"count_classes\".!=maximum(df.\"count_classes\"),:].\"count_classes\") <= max_elements_small_classes\n",
    "            if sum(df[df.\"classes\".!=df[1,1],\"count_classes\"])<= max_elements_small_classes\n",
    "                remainingClusters -=1\n",
    "                if remainingClusters < num_clusters\n",
    "                    break\n",
    "                end\n",
    "                merge!(c1, c2) #On merge les 2 clusters\n",
    "                for id in c2.dataIds \n",
    "                    clusterId[id]= cId1 #On modifie le clusterId dans la serie pour le cluster_2, on lui affecte le cluster_1\n",
    "                end\n",
    "                # Vider le second cluster\n",
    "                empty!(clusters[cId2].dataIds)\n",
    "            end\n",
    "\n",
    "        end\n",
    "        distanceId += 1\n",
    "    end\n",
    "    df_clusters = DataFrame()\n",
    "    df_clusters.\"cluster_id\" = collect(keys(StatsBase.countmap(clusterId)))\n",
    "    df_clusters.\"number_elements\" = collect(values(StatsBase.countmap(clusterId)))\n",
    "    higher_than_threshold(value::Int64) = value >= 1\n",
    "    clusters_to_treat = filter(:\"number_elements\"=> higher_than_threshold, df_clusters).\"cluster_id\"\n",
    "    for cluster_interest in clusters_to_treat\n",
    "        clusters = update_clusters(\n",
    "            clusters,\n",
    "            cluster_interest,\n",
    "            clusterId,\n",
    "            y\n",
    "        )   \n",
    "    end\n",
    "    return filter(x -> length(x.dataIds) > 0, clusters)\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
