{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"src\\\\building_tree.jl\")\n",
    "include(\"src\\\\utilities.jl\")\n",
    "include(\"src\\\\merge.jl\")\n",
    "using Debugger\n",
    "using DataFrames, Random\n",
    "using DataStructures\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using LinearAlgebra\n",
    "using LazySets\n",
    "using Polyhedra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (train size 120, test size 30, 4, features count: 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120-element Vector{Int64}:\n",
       " 3\n",
       " 1\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " ⋮\n",
       " 3\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataSetName = \"iris\"\n",
    "include(\"./data/\" * dataSetName * \".txt\")\n",
    "# Ramener chaque caractéristique sur [0, 1]\n",
    "reducedX = Matrix{Float64}(X)\n",
    "for j in 1:size(X, 2)\n",
    "    reducedX[:, j] .-= minimum(X[:, j])\n",
    "    reducedX[:, j] ./= maximum(X[:, j])\n",
    "end\n",
    "\n",
    "train, test = train_test_indexes(length(Y))\n",
    "X_train = reducedX[train,:]\n",
    "Y_train = Y[train]\n",
    "X_test = reducedX[test,:]\n",
    "Y_test = Y[test]\n",
    "classes = unique(Y)\n",
    "\n",
    "println(\" (train size \", size(X_train, 1), \", test size \", size(X_test, 1), \", \", size(X_train, 2), \", features count: \", size(X_train, 2), \")\")\n",
    "\n",
    "# Temps limite de la\n",
    "time_limit = 10\n",
    "D = 3\n",
    "x = X_train\n",
    "y = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Int64}:\n",
       "  7\n",
       "  1\n",
       "  1\n",
       " 21\n",
       " 43\n",
       " 40\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = length(Y_train)\n",
    "m = length(x[1,:])\n",
    "clusters = Vector{Cluster}([])\n",
    "for dataId in 1:size(x,1)\n",
    "    push!(clusters, Cluster(dataId, x,y))\n",
    "end\n",
    "clusterId = collect(1:n) #On obtient un vecteur 1,2..., qui correspond pour chaque cluster à son clusterId\n",
    "distances = Vector{Distance}([])\n",
    "for id1 in 1:n-1\n",
    "    for id2 in id1+1:n\n",
    "        push!(distances, Distance(id1, id2, x))\n",
    "    end\n",
    "end\n",
    "sort!(distances, by = v ->v.distance)\n",
    "remainingClusters=n\n",
    "distanceId = 1\n",
    "n_epochs = 1\n",
    "c1_bis = Nothing\n",
    "c2_bis = Nothing\n",
    "i = 1\n",
    "a=i\n",
    "max_elements_small_classes = 5\n",
    "num_clusters = 10\n",
    "\n",
    "while remainingClusters>= num_clusters\n",
    "    distance = distances[distanceId]\n",
    "    cId1 =clusterId[distance.ids[1]]\n",
    "    cId2 = clusterId[distance.ids[2]]\n",
    "    if cId1 != cId2\n",
    "        c1 = clusters[cId1]\n",
    "        c2 = clusters[cId2]\n",
    "        count_classes_in_clusters = StatsBase.countmap([y[c2.dataIds]; y[c1.dataIds]])\n",
    "        df = DataFrame()\n",
    "        df.\"classes\" = collect(keys(count_classes_in_clusters))\n",
    "        df.\"count_classes\" = collect(values(count_classes_in_clusters))\n",
    "        df = sort(df, [:count_classes], rev=true)\n",
    "        # if sum(df[df.\"count_classes\".!=maximum(df.\"count_classes\"),:].\"count_classes\") <= max_elements_small_classes\n",
    "        if sum(df[df.\"classes\".!=df[1,1],\"count_classes\"])<= max_elements_small_classes\n",
    "            remainingClusters -=1\n",
    "            if remainingClusters < num_clusters\n",
    "                break\n",
    "            end\n",
    "            merge!(c1, c2) #On merge les 2 clusters\n",
    "            for id in c2.dataIds \n",
    "                clusterId[id]= cId1 #On modifie le clusterId dans la serie pour le cluster_2, on lui affecte le cluster_1\n",
    "            end\n",
    "            # Vider le second cluster\n",
    "            empty!(clusters[cId2].dataIds)\n",
    "        end\n",
    "\n",
    "    end\n",
    "    distanceId += 1\n",
    "    # if i % 50 == 0\n",
    "    # #     println(remainingClusters)\n",
    "    # #     # print(\"\\n\")\n",
    "    # # end\n",
    "end\n",
    "df_clusters = DataFrame()\n",
    "df_clusters.\"cluster_id\" = collect(keys(StatsBase.countmap(clusterId)))\n",
    "df_clusters.\"number_elements\" = collect(values(StatsBase.countmap(clusterId)))\n",
    "# higher_than_threshold(value::Int64) = value >= 10\n",
    "# clusters_to_treat = filter(:\"number_elements\"=> higher_than_threshold, df_clusters).\"cluster_id\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only one class in cluster\n",
      ", we are not touching cluster 41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "120only one class in cluster\n",
      ", we are not touching cluster 38\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "120"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "several classes in clusterglp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "glp_simplex: unable to recover undefined or non-optimal solution\n",
      "1 true\n",
      "2 true\n",
      "3 false\n",
      "4 false\n",
      "5 false\n",
      "123"
     ]
    }
   ],
   "source": [
    "for cluster_interest in clusters_to_treat \n",
    "    count_classes_in_clusters = StatsBase.countmap(y[findall(x->x==cluster_interest, clusterId)])\n",
    "    y_cluster = y[findall(x->x==cluster_interest, clusterId)]\n",
    "    df = DataFrame()\n",
    "    df.\"classes\" = collect(keys(count_classes_in_clusters))\n",
    "    df.\"count_classes\" = collect(values(count_classes_in_clusters))\n",
    "    df = sort(df, [:count_classes], rev=true)\n",
    "    main_class = 0\n",
    "    if size(df)[1]>1\n",
    "        main_class = df[1,1]\n",
    "        print(\"several classes in cluster\")\n",
    "    else\n",
    "        println(\"only one class in cluster\")\n",
    "        println(\", we are not touching cluster \", cluster_interest)\n",
    "        main_class = df[1,1]\n",
    "    end   \n",
    "    points_in_cluster = findall(x->x==cluster_interest, clusterId)\n",
    "    points_reckon_with = Vector{Int64}([])\n",
    "    points_sideline = Vector{Int64}([])\n",
    "    for (i, point) in enumerate(points_in_cluster)\n",
    "        if y[point] != main_class\n",
    "            push!(points_sideline,i )\n",
    "        else\n",
    "            push!(points_reckon_with, i)\n",
    "        end\n",
    "    end\n",
    "    matrix_interest = clusters[cluster_interest].x\n",
    "    size(matrix_interest, 1)\n",
    "    vectors_cluster = [matrix_interest[i,:] for i in 1:size(matrix_interest,1)]\n",
    "    vectors_cluster[points_reckon_with]\n",
    "    hull = LazySets.convex_hull(vectors_cluster[points_reckon_with])\n",
    "    for i in 1:length(points_sideline)\n",
    "        println(i, \" \",element(Singleton(vectors_cluster[points_sideline[i]])) ∈ VPolytope(hull))\n",
    "        if element(Singleton(vectors_cluster[points_sideline[i]])) ∈ VPolytope(hull)\n",
    "            push!(points_reckon_with,  points_sideline[i])\n",
    "        end\n",
    "    end\n",
    "    sort!(points_reckon_with)\n",
    "    points_to_be_taken_out_cluster = points_sideline[points_sideline .∉ Ref(points_reckon_with)]\n",
    "\n",
    "    new_clusters = Vector{Cluster}([])\n",
    "    point_cluster  = points_reckon_with[1]\n",
    "    trimmed_cluster = Cluster(point_cluster, matrix_interest, y_cluster)\n",
    "    for point_cluster in points_reckon_with[2:end]\n",
    "        new_cluster = Cluster(point_cluster, matrix_interest, y_cluster)\n",
    "        merge!(trimmed_cluster, new_cluster)\n",
    "    end\n",
    "\n",
    "    for point_cluster in points_to_be_taken_out_cluster\n",
    "        new_cluster = Cluster(point_cluster, matrix_interest, y_cluster)\n",
    "        push!(clusters, new_cluster)\n",
    "    end\n",
    "    clusters[cluster_interest] = trimmed_cluster\n",
    "    print(length(clusters))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
